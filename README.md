# GigaVAD

Инструменты для пакетной обработки диктовок: детекция голосовой активности (VAD), упаковка сегментов и распознавание речи моделями [Salute GigaAM](https://github.com/salute-developers/GigaAM). Центральный сценарий `inference_gigaam.py` обходит каталоги с аудиофайлами, вырезает фрагменты речи с помощью Silero VAD, распознаёт их и собирает финальные диалоги.

## Состав репозитория
- **`inference_gigaam.py`** — основной конвейер обработки каталогов с записями. Управляет Silero VAD, упаковкой сегментов, вызовом GigaAM и формированием итоговых файлов (`transcript.json`, `dialog_*.jsonl`, `dialog_*.txt`).
- **`vad_module.py`** — тонкая обёртка над Silero VAD с дополнительными опциями паддинга, фильтрации и слияния сегментов.
- **`rupunct_apply.py`** — утилита для расстановки русской пунктуации и регистра с помощью модели [RUPunct_big](https://huggingface.co/RUPunct/RUPunct_big). Используется и как отдельный CLI, и из `inference_gigaam.py`, если доступна зависимость.

## Установка
1. Подготовьте окружение Python 3.10+.
2. Установите зависимости:
   ```bash
   pip install -r requirements.txt
   ```
3. Библиотека `gigaam` подключается как опциональная зависимость. Если пакета нет в PyPI вашей системы, установите его напрямую из GitHub:
   ```bash
   pip install git+https://github.com/salute-developers/GigaAM
   ```
4. Для офлайн-запуска Silero VAD скачайте `model.jit` и `utils_vad.py` из репозитория [snakers4/silero-vad](https://github.com/snakers4/silero-vad) и укажите путь в параметре `SILERO_MODEL_DIR`.

## Подготовка данных
- Скрипт ожидает дерево каталогов с аудиофайлами в формате WAV/FLAC/MP3/M4A/AAC/OGG/OPUS.
- По умолчанию корневой каталог задаётся константой `INPUT = "records"`. Поменяйте её, если исходные записи лежат в другом месте.
- Вложенная структура каталогов сохраняется в выходных данных: для каждой подпапки создаётся собственный набор файлов результатов.

## Настройка конвейера
Основные параметры задаются в верхней части `inference_gigaam.py`.

| Параметр | Назначение |
| --- | --- |
| `OUTPUT` | Путь к файлу агрегированного JSON с расшифровками (будет создан в зеркальной структуре относительно входных каталогов). |
| `OUTPUT_FORMAT` | Если значение `"txt"`, дополнительно формируется текстовый отчёт `OUTPUT_REPORT`. |
| `WRITE_SEGMENTS` | Базовая папка для хранения `*_segments.jsonl`, `dialog_*.jsonl` и `dialog_*.txt`. |
| `MODEL_NAME`, `LANG` | Идентификатор модели GigaAM и язык распознавания. |
| Блок **Silero** | Параметры VAD: порог срабатывания, минимальная длина речи, паддинг и т.д. |
| Блок **VAD_PACK_BINS** | Управление упаковкой сегментов в бины фиксированной длины без разрезания середины фраз. |
| `MAX_DIALOG_GAP_SEC` | Максимальная пауза между сегментами одного файла при сборке диалога. |
| `PUNCT_RU` | Включает пунктуацию с помощью RUPunct (требуются `transformers` и модель `RUPunct_big`). |

При необходимости правьте и другие параметры (отбор файлов, фильтры качества текста, использование временных файлов и т.п.).

## Запуск распознавания
После настройки констант выполните из корня репозитория:

```bash
python inference_gigaam.py
```

Скрипт автоматически создаёт локальные директории `.torch` и `.tmp` для кэшей и временных файлов. Если доступен GPU, Silero и GigaAM будут использовать CUDA.

## Результаты работы
Для каждой обработанной подпапки входного каталога формируются следующие файлы (пути указаны относительно `WRITE_SEGMENTS`/`OUTPUT`):

- `<subdir>/transcript.json` — агрегированный JSON вида `{ "audio.wav": "полный текст" }`.
- `<subdir>/transcript_results.txt` — текстовый отчёт (создаётся только при `OUTPUT_FORMAT = "txt"`).
- `<subdir>/<имя_аудио>_segments.jsonl` — построчные сегменты с таймкодами и распознанным текстом.
- `<subdir>/dialog_<subdir>.jsonl` — объединённый диалог с таймкодами после слияния соседних реплик.
- `<subdir>/dialog_<subdir>.txt` — "очищенная" версия диалога (по одной реплике на строку в формате `имя: "текст"`).

Если активирован `PUNCT_RU` и зависимости доступны, сегменты диалога дополнительно проходят через RUPunct; ошибки загрузки модели не прерывают обработку.

## Отдельная расстановка пунктуации
Скрипт `rupunct_apply.py` можно запускать самостоятельно для уже готовых сегментов JSONL:

```bash
python rupunct_apply.py --in path/to/segments.jsonl \
    --out path/to/segments_punct.jsonl \
    --merge_json path/to/transcript_punct.json
```

На выходе получаются сегменты с полем `text_punct` и, при указании `--merge_json`, агрегированный JSON с восстановленной пунктуацией.

## Разработка
- Для быстрой проверки синтаксиса используйте `python -m py_compile inference_gigaam.py rupunct_apply.py`.
- Автоматических unit-тестов в репозитории нет; проверяйте изменения на реальных данных перед выкладкой.
